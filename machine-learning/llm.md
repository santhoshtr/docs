
* [Understanding Large Language Models](https://arxiv.org/abs/1510.00726s) -- A Transformative Reading List - Sebastian's whole site is very worth reading, start with this survey of LLM posts and literature
* [A Primer on Neural Network Models for Natural Language Processing](https://arxiv.org/abs/1510.00726) - Good idea to read everything Yoav has written but this is a great start
* Figures Everyone Should Know https://github.com/ray-project/llm-numbers
* Transformers from Scratch - This is the one I come back to every time. https://e2eml.school/transformers.html
* Illustrated Word2Vec - Jay's site is extremely good, this one is particularly good for Word2Vec https://jalammar.github.io/illustrated-word2vec/
* Attention? Attention! - Deep dive into the attention mechanism.
A History of NLP - Great summary of the field over the last 20 or so years. https://lilianweng.github.io/posts/2018-06-24-attention/
* Dive into Deep Learning Course https://d2l.ai/index.html
* https://arstechnica.com/science/2023/07/a-jargon-free-explanation-of-how-ai-large-language-models-work/

https://ig.ft.com/generative-ai/

## Local language  - LLMS

* Kannada LLAMA https://www.tensoic.com/blog/kannada-llama/
* Malaysian Mistral https://github.com/mesolitica/research-paper/blob/master/malaysian-mistral.pdf
* MaLLaM Malaysia Large Language Model https://github.com/mesolitica/research-paper/blob/master/mallam.pdf https://huggingface.co/mesolitica/mallam-1.1B-4096

